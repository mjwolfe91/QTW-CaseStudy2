{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(XML)\n",
    "ubase = \"http://www.cherryblossom.org/\"\n",
    "\n",
    "#### From text\n",
    "menURLs = \n",
    "  c(\"cb99m.htm\", \n",
    "    \"cb003m.htm\", \n",
    "    \"results/2001/oof_m.html\",\n",
    "    \"results/2002/oofm.htm\", \n",
    "    \"results/2003/CB03-M.HTM\",\n",
    "    \"results/2004/men.htm\", \n",
    "    \"results/2005/CB05-M.htm\", \n",
    "    \"results/2006/men.htm\", \n",
    "    \"results/2007/men.htm\", \n",
    "    \"results/2008/men.htm\", \n",
    "    \"results/2009/09cucb-M.htm\",\n",
    "    \"results/2010/2010cucb10m-m.htm\", \n",
    "    \"results/2011/2011cucb10m-m.htm\",\n",
    "    \"results/2012/2012cucb10m-m.htm\")\n",
    "####\n",
    "\n",
    "#### Text URLS\n",
    "urls = paste(ubase, menURLs, sep=\"\")\n",
    "urls[1:4]\n",
    "\n",
    "# 1999: http://www.cherryblossom.org/cb99m.htm\n",
    "# 2000: http://www.cherryblossom.org/cb003m.htm\n",
    "# 2001: http://www.cherryblossom.org/results/2001/oof_m.html\n",
    "\n",
    "#### Textbook Function\n",
    "extractResTable =\n",
    "  #\n",
    "  # Retrieve data from web site, \n",
    "  # find the preformatted text,\n",
    "  # and write lines or return as a character vector.\n",
    "  #\n",
    "  function(url = \"http://www.cherryblossom.org/results/2009/09cucb-F.htm\",\n",
    "           year = 1999, sex = \"male\", file = NULL)\n",
    "  {\n",
    "    #added encoding for windows users who get an \"A\" symbol\n",
    "    doc = htmlParse(url)    \n",
    "    #doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "    \n",
    "    if (year == 2000) {\n",
    "      # Get preformatted text from 4th font element\n",
    "      # The top file is ill formed so the <pre> search doesn't work.\n",
    "      ff = getNodeSet(doc, \"//font\")\n",
    "      txt = xmlValue(ff[[4]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "    }\n",
    "    else if (year == 2009 & sex == \"male\") {\n",
    "      # Get preformatted text from <div class=\"Section1\"> element\n",
    "      # Each line of results is in a <pre> element\n",
    "      div1 = getNodeSet(doc, \"//div[@class='Section1']\")\n",
    "      pres = getNodeSet(div1[[1]], \"//pre\")\n",
    "      els = sapply(pres, xmlValue)\n",
    "    }\n",
    "    else {\n",
    "      # Get preformatted text from <pre> elements\n",
    "      pres = getNodeSet(doc, \"//pre\")\n",
    "      txt = xmlValue(pres[[1]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "#      els2 = strsplit(txt, \"\\n\")[[1]]\n",
    "    } \n",
    "    \n",
    "    if (is.null(file)) return(els)\n",
    "    # Write the lines as a text file.\n",
    "    writeLines(els, con = file)\n",
    "  }\n",
    "\n",
    "# Skip over the first pass\n",
    "#### Individual Input Components for Testing: 1999\n",
    "url <- 'http://www.cherryblossom.org/results/1999/cb99m.html'\n",
    "year <- 1999\n",
    "sex <- \"male\"\n",
    "file <- NULL\n",
    "####\n",
    "\n",
    "# Skip over the first pass\n",
    "#### Individual Input Components for Testing: 2000\n",
    "url <- 'http://www.cherryblossom.org/results/2000/Cb003m.htm'\n",
    "year <- 2000\n",
    "sex <- \"male\"\n",
    "file <- NULL\n",
    "####\n",
    "\n",
    "#### Textbook example with (1) URL\n",
    "df1 <- extractResTable(url = \"http://www.cherryblossom.org/results/2000/Cb003m.htm\", year = 2000, sex = \"male\", file = NULL)\n",
    "df2 <- extractResTable(url = \"http://www.cherryblossom.org/results/1999/cb99m.html\", year = 1999, sex = \"male\", file = NULL)\n",
    "#df3 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/1999/cb99m.html\", year = 1999, sex = \"male\", file = NULL)\n",
    "\n",
    "#### Textbook extraction of Male tables (results in an error)\n",
    "years = 1999:2012\n",
    "menTables = mapply(extractResTable, url = urls, year = years)\n",
    "#names(menTables) = years # can't run b/c menTables hasn't been created\n",
    "#sapply(menTables, length) # can't run b/c menTables hasn't been created\n",
    "\n",
    "menTables <- list()\n",
    "for(i in 1:length(years)){\n",
    "  menTables[[i]] <- try(extractResTable(url=urls[i], year=years[i]))\n",
    "}\n",
    "\n",
    "# Let's go check out the first two URLs\n",
    "urls[1] # [1] \"http://www.cherryblossom.org/cb99m.htm\"\n",
    "urls[2] # [1] \"http://www.cherryblossom.org/cb003m.htm\"\n",
    "\n",
    "#### Revised URLS\n",
    "menURLsV2 = \n",
    "  c(\"results/1999/cb99m.html\", #\"cb99m.htm\"\n",
    "    \"results/2000/Cb003m.htm\", #\"cb003m.htm\"\n",
    "    \"results/2001/oof_m.html\", #\"results/2001/oof_m.html\"\n",
    "    \"results/2002/oofm.htm\", #\"results/2002/oofm.htm\"\n",
    "    \"results/2003/CB03-M.HTM\", #\"results/2003/CB03-M.HTM\"\n",
    "    \"results/2004/men.htm\", #\"results/2004/men.htm\"\n",
    "    \"results/2005/CB05-M.htm\", #\"results/2005/CB05-M.htm\"\n",
    "    \"results/2006/men.htm\", #\"results/2006/men.htm\"\n",
    "    \"results/2007/men.htm\", #\"results/2007/men.htm\"\n",
    "    \"results/2008/men.htm\", #\"results/2008/men.htm\"\n",
    "    \"results/2009/09cucb-M.htm\", #\"results/2009/09cucb-M.htm\"\n",
    "    \"results/2010/2010cucb10m-m.htm\", #\"results/2010/2010cucb10m-m.htm\"\n",
    "    \"results/2011/2011cucb10m-m.htm\", #\"results/2011/2011cucb10m-m.htm\"\n",
    "    \"results/2012/2012cucb10m-m.htm\" #\"results/2012/2012cucb10m-m.htm\"\n",
    "  )\n",
    "####\n",
    "\n",
    "#### Revised URLS\n",
    "urlsV2 = paste(ubase, menURLsV2, sep=\"\")\n",
    "urlsV2[1:4]\n",
    "\n",
    "#### Modified textbook extraction of Male tables (results in 1999 having (1) record)\n",
    "menTables = mapply(extractResTable, url = urlsV2, year = years)\n",
    "names(menTables) = years\n",
    "sapply(menTables, length)\n",
    "\n",
    "#### Code to compare and contrast the format of two different years\n",
    "substr(menTables$'1999', start = 1, stop = 100)\n",
    "substr(menTables$'2000', start = 1, stop = 100)\n",
    "menTables$'2000'[1:10]\n",
    "\n",
    "#### Revised Function\n",
    "extractResTableV2 =\n",
    "  #\n",
    "  # Retrieve data from web site, \n",
    "  # find the preformatted text,\n",
    "  # and write lines or return as a character vector.\n",
    "  #\n",
    "  function(url = \"http://www.cherryblossom.org/results/2009/09cucb-F.htm\",\n",
    "           year = 1999, sex = \"male\", file = NULL)\n",
    "  {\n",
    "    #added encoding for windows users who get an \"A\" symbol\n",
    "    doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "    \n",
    "    if (year == 2000) {\n",
    "      # Get preformatted text from 4th font element\n",
    "      # The top file is ill formed so the <pre> search doesn't work.\n",
    "      ff = getNodeSet(doc, \"//font\")\n",
    "      txt = xmlValue(ff[[4]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "    }\n",
    "    else if (year == 2009 & sex == \"male\") {\n",
    "      # Get preformatted text from <div class=\"Section1\"> element\n",
    "      # Each line of results is in a <pre> element\n",
    "      div1 = getNodeSet(doc, \"//div[@class='Section1']\")\n",
    "      pres = getNodeSet(div1[[1]], \"//pre\")\n",
    "      els = sapply(pres, xmlValue)\n",
    "    }\n",
    "    else if (year == 1999 & sex == \"male\") { # have to add this else if statement\n",
    "      # Get preformatted text from <pre> elements\n",
    "      pres = getNodeSet(doc, \"//pre\")\n",
    "      txt = xmlValue(pres[[1]])\n",
    "      els = strsplit(txt, \"\\n\")[[1]]   \n",
    "    } \n",
    "    else {\n",
    "      # Get preformatted text from <pre> elements\n",
    "      pres = getNodeSet(doc, \"//pre\")\n",
    "      txt = xmlValue(pres[[1]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]   \n",
    "    } \n",
    "    \n",
    "    if (is.null(file)) return(els)\n",
    "    # Write the lines as a text file.\n",
    "    writeLines(els, con = file)\n",
    "  }\n",
    "\n",
    "#### Corrected function to pull down Male tables with consistent format\n",
    "menTablesV2 = mapply(extractResTableV2, url = urlsV2, year = years)\n",
    "names(menTablesV2) = years\n",
    "sapply(menTablesV2, length)\n",
    "\n",
    "#### Confirmation that the 1999 and other years have consistent formatting\n",
    "menTablesV2$'1999'[1:10]\n",
    "menTablesV2[[2]][1:10]\n",
    "\n",
    "#### Save the outputs\n",
    "save(menTablesV2, file = \"CBMenTextTables.rda\")\n",
    "\n",
    "#### Now we need to investigate the differences between the male and female result pages\n",
    "# 2000\n",
    "df_male_2000 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2000/Cb003m.htm\", year = 2000, sex = \"male\", file = NULL)\n",
    "df_female_2000 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2000/Cb003f.htm\", year = 2000, sex = \"female\", file = NULL)\n",
    "\n",
    "df_female_2000[1:10]\n",
    "df_male_2000[1:10]\n",
    "\n",
    "# 2006\n",
    "df_male_2006 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2006/men.htm\", year = 2006, sex = \"male\", file = NULL)\n",
    "df_female_2006 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2006/women.htm\", year = 2006, sex = \"female\", file = NULL)\n",
    "\n",
    "df_female_2006[1:10]\n",
    "df_male_2006[1:10]\n",
    "\n",
    "######################################################################\n",
    "# Miscellaneous Code\n",
    "\n",
    "menTables <- list()\n",
    "for(i in 1:length(years)){\n",
    "  menTables[[i]] <- try(extractResTable(url=urlsV2[i], year=years[i]))\n",
    "}\n",
    "\n",
    "# Breaking down the extractResTableV2 for 1999 - Men\n",
    "url <- urlsV2[1]\n",
    "doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "pres = getNodeSet(doc, \"//pre\")\n",
    "txt = xmlValue(pres[[1]])\n",
    "els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "els = strsplit(txt, \"\\n\")[[1]]\n",
    "\n",
    "# Breaking down the extractResTableV2 for 2009 - Men\n",
    "url <- urlsV2[11]\n",
    "doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "div1 = getNodeSet(doc, \"//div[@class='Section1']\")\n",
    "pres = getNodeSet(div1[[1]], \"//pre\")\n",
    "els = sapply(pres, xmlValue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.cherryblossom.org/cb003m.htm',\n",
       " 'http://www.cherryblossom.org/results/2001/oof_m.html',\n",
       " 'http://www.cherryblossom.org/results/2002/oofm.htm']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubase = \"http://www.cherryblossom.org/\"\n",
    "menURLs = [\"cb99m.htm\", \n",
    "    \"cb003m.htm\", \n",
    "    \"results/2001/oof_m.html\",\n",
    "    \"results/2002/oofm.htm\", \n",
    "    \"results/2003/CB03-M.HTM\",\n",
    "    \"results/2004/men.htm\", \n",
    "    \"results/2005/CB05-M.htm\", \n",
    "    \"results/2006/men.htm\", \n",
    "    \"results/2007/men.htm\", \n",
    "    \"results/2008/men.htm\", \n",
    "    \"results/2009/09cucb-M.htm\",\n",
    "    \"results/2010/2010cucb10m-m.htm\", \n",
    "    \"results/2011/2011cucb10m-m.htm\",\n",
    "    \"results/2012/2012cucb10m-m.htm\"]\n",
    "urls = [ubase + s for s in menURLs]\n",
    "urls[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Place Num   Name                  Ag Hometown           Net     Gun'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'http://www.cherryblossom.org/results/2002/oofm.htm'\n",
    "\n",
    "response = urllib.request.urlopen(URL)\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.find(\"pre\").find(text=True)\n",
    "raw_rows = [x.strip() for x in table.split('\\n')]\n",
    "table_cols = raw_rows[1]\n",
    "table_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['688', '4639', 'Donald MOATS', 'JR', '38', 'Chambersburg PA', '1:14:12', '1:14:48']\n",
      "['2466', '2163', 'Paul CRUM', 'SR', '72', 'Jacksonville FL', '1:29:51', '1:34:08']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "table = soup.find(\"pre\").find(text=True)\n",
    "raw_rows = [x.strip() for x in table.split('\\r\\n')]\n",
    "table_cols = raw_rows[1].split()\n",
    "parsed_rows = []\n",
    "for row in raw_rows[3:]:\n",
    "    parsed_rows.append(re.split(r'\\s{2,}|(?<=[0-9])\\s', row))\n",
    "for row in parsed_rows:\n",
    "    if len(row) > 7:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(XML)\n",
    "ubase = \"http://www.cherryblossom.org/\"\n",
    "\n",
    "#### From text\n",
    "menURLs = \n",
    "  c(\"cb99m.htm\", \n",
    "    \"cb003m.htm\", \n",
    "    \"results/2001/oof_m.html\",\n",
    "    \"results/2002/oofm.htm\", \n",
    "    \"results/2003/CB03-M.HTM\",\n",
    "    \"results/2004/men.htm\", \n",
    "    \"results/2005/CB05-M.htm\", \n",
    "    \"results/2006/men.htm\", \n",
    "    \"results/2007/men.htm\", \n",
    "    \"results/2008/men.htm\", \n",
    "    \"results/2009/09cucb-M.htm\",\n",
    "    \"results/2010/2010cucb10m-m.htm\", \n",
    "    \"results/2011/2011cucb10m-m.htm\",\n",
    "    \"results/2012/2012cucb10m-m.htm\")\n",
    "####\n",
    "\n",
    "#### Text URLS\n",
    "urls = paste(ubase, menURLs, sep=\"\")\n",
    "urls[1:4]\n",
    "\n",
    "# 1999: http://www.cherryblossom.org/cb99m.htm\n",
    "# 2000: http://www.cherryblossom.org/cb003m.htm\n",
    "# 2001: http://www.cherryblossom.org/results/2001/oof_m.html\n",
    "\n",
    "#### Textbook Function\n",
    "extractResTable =\n",
    "  #\n",
    "  # Retrieve data from web site, \n",
    "  # find the preformatted text,\n",
    "  # and write lines or return as a character vector.\n",
    "  #\n",
    "  function(url = \"http://www.cherryblossom.org/results/2009/09cucb-F.htm\",\n",
    "           year = 1999, sex = \"male\", file = NULL)\n",
    "  {\n",
    "    #added encoding for windows users who get an \"A\" symbol\n",
    "    doc = htmlParse(url)    \n",
    "    #doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "    \n",
    "    if (year == 2000) {\n",
    "      # Get preformatted text from 4th font element\n",
    "      # The top file is ill formed so the <pre> search doesn't work.\n",
    "      ff = getNodeSet(doc, \"//font\")\n",
    "      txt = xmlValue(ff[[4]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "    }\n",
    "    else if (year == 2009 & sex == \"male\") {\n",
    "      # Get preformatted text from <div class=\"Section1\"> element\n",
    "      # Each line of results is in a <pre> element\n",
    "      div1 = getNodeSet(doc, \"//div[@class='Section1']\")\n",
    "      pres = getNodeSet(div1[[1]], \"//pre\")\n",
    "      els = sapply(pres, xmlValue)\n",
    "    }\n",
    "    else {\n",
    "      # Get preformatted text from <pre> elements\n",
    "      pres = getNodeSet(doc, \"//pre\")\n",
    "      txt = xmlValue(pres[[1]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "#      els2 = strsplit(txt, \"\\n\")[[1]]\n",
    "    } \n",
    "    \n",
    "    if (is.null(file)) return(els)\n",
    "    # Write the lines as a text file.\n",
    "    writeLines(els, con = file)\n",
    "  }\n",
    "\n",
    "# Skip over the first pass\n",
    "#### Individual Input Components for Testing: 1999\n",
    "url <- 'http://www.cherryblossom.org/results/1999/cb99m.html'\n",
    "year <- 1999\n",
    "sex <- \"male\"\n",
    "file <- NULL\n",
    "####\n",
    "\n",
    "# Skip over the first pass\n",
    "#### Individual Input Components for Testing: 2000\n",
    "url <- 'http://www.cherryblossom.org/results/2000/Cb003m.htm'\n",
    "year <- 2000\n",
    "sex <- \"male\"\n",
    "file <- NULL\n",
    "####\n",
    "\n",
    "#### Textbook example with (1) URL\n",
    "df1 <- extractResTable(url = \"http://www.cherryblossom.org/results/2000/Cb003m.htm\", year = 2000, sex = \"male\", file = NULL)\n",
    "df2 <- extractResTable(url = \"http://www.cherryblossom.org/results/1999/cb99m.html\", year = 1999, sex = \"male\", file = NULL)\n",
    "#df3 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/1999/cb99m.html\", year = 1999, sex = \"male\", file = NULL)\n",
    "\n",
    "#### Textbook extraction of Male tables (results in an error)\n",
    "years = 1999:2012\n",
    "menTables = mapply(extractResTable, url = urls, year = years)\n",
    "#names(menTables) = years # can't run b/c menTables hasn't been created\n",
    "#sapply(menTables, length) # can't run b/c menTables hasn't been created\n",
    "\n",
    "menTables <- list()\n",
    "for(i in 1:length(years)){\n",
    "  menTables[[i]] <- try(extractResTable(url=urls[i], year=years[i]))\n",
    "}\n",
    "\n",
    "# Let's go check out the first two URLs\n",
    "urls[1] # [1] \"http://www.cherryblossom.org/cb99m.htm\"\n",
    "urls[2] # [1] \"http://www.cherryblossom.org/cb003m.htm\"\n",
    "\n",
    "#### Revised URLS\n",
    "menURLsV2 = \n",
    "  c(\"results/1999/cb99m.html\", #\"cb99m.htm\"\n",
    "    \"results/2000/Cb003m.htm\", #\"cb003m.htm\"\n",
    "    \"results/2001/oof_m.html\", #\"results/2001/oof_m.html\"\n",
    "    \"results/2002/oofm.htm\", #\"results/2002/oofm.htm\"\n",
    "    \"results/2003/CB03-M.HTM\", #\"results/2003/CB03-M.HTM\"\n",
    "    \"results/2004/men.htm\", #\"results/2004/men.htm\"\n",
    "    \"results/2005/CB05-M.htm\", #\"results/2005/CB05-M.htm\"\n",
    "    \"results/2006/men.htm\", #\"results/2006/men.htm\"\n",
    "    \"results/2007/men.htm\", #\"results/2007/men.htm\"\n",
    "    \"results/2008/men.htm\", #\"results/2008/men.htm\"\n",
    "    \"results/2009/09cucb-M.htm\", #\"results/2009/09cucb-M.htm\"\n",
    "    \"results/2010/2010cucb10m-m.htm\", #\"results/2010/2010cucb10m-m.htm\"\n",
    "    \"results/2011/2011cucb10m-m.htm\", #\"results/2011/2011cucb10m-m.htm\"\n",
    "    \"results/2012/2012cucb10m-m.htm\" #\"results/2012/2012cucb10m-m.htm\"\n",
    "  )\n",
    "####\n",
    "\n",
    "#### Revised URLS\n",
    "urlsV2 = paste(ubase, menURLsV2, sep=\"\")\n",
    "urlsV2[1:4]\n",
    "\n",
    "#### Modified textbook extraction of Male tables (results in 1999 having (1) record)\n",
    "menTables = mapply(extractResTable, url = urlsV2, year = years)\n",
    "names(menTables) = years\n",
    "sapply(menTables, length)\n",
    "\n",
    "#### Code to compare and contrast the format of two different years\n",
    "substr(menTables$'1999', start = 1, stop = 100)\n",
    "substr(menTables$'2000', start = 1, stop = 100)\n",
    "menTables$'2000'[1:10]\n",
    "\n",
    "#### Revised Function\n",
    "extractResTableV2 =\n",
    "  #\n",
    "  # Retrieve data from web site, \n",
    "  # find the preformatted text,\n",
    "  # and write lines or return as a character vector.\n",
    "  #\n",
    "  function(url = \"http://www.cherryblossom.org/results/2009/09cucb-F.htm\",\n",
    "           year = 1999, sex = \"male\", file = NULL)\n",
    "  {\n",
    "    #added encoding for windows users who get an \"A\" symbol\n",
    "    doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "    \n",
    "    if (year == 2000) {\n",
    "      # Get preformatted text from 4th font element\n",
    "      # The top file is ill formed so the <pre> search doesn't work.\n",
    "      ff = getNodeSet(doc, \"//font\")\n",
    "      txt = xmlValue(ff[[4]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "    }\n",
    "    else if (year == 2009 & sex == \"male\") {\n",
    "      # Get preformatted text from <div class=\"Section1\"> element\n",
    "      # Each line of results is in a <pre> element\n",
    "      div1 = getNodeSet(doc, \"//div[@class='Section1']\")\n",
    "      pres = getNodeSet(div1[[1]], \"//pre\")\n",
    "      els = sapply(pres, xmlValue)\n",
    "    }\n",
    "    else if (year == 1999 & sex == \"male\") { # have to add this else if statement\n",
    "      # Get preformatted text from <pre> elements\n",
    "      pres = getNodeSet(doc, \"//pre\")\n",
    "      txt = xmlValue(pres[[1]])\n",
    "      els = strsplit(txt, \"\\n\")[[1]]   \n",
    "    } \n",
    "    else {\n",
    "      # Get preformatted text from <pre> elements\n",
    "      pres = getNodeSet(doc, \"//pre\")\n",
    "      txt = xmlValue(pres[[1]])\n",
    "      els = strsplit(txt, \"\\r\\n\")[[1]]   \n",
    "    } \n",
    "    \n",
    "    if (is.null(file)) return(els)\n",
    "    # Write the lines as a text file.\n",
    "    writeLines(els, con = file)\n",
    "  }\n",
    "\n",
    "#### Corrected function to pull down Male tables with consistent format\n",
    "menTablesV2 = mapply(extractResTableV2, url = urlsV2, year = years)\n",
    "names(menTablesV2) = years\n",
    "sapply(menTablesV2, length)\n",
    "\n",
    "#### Confirmation that the 1999 and other years have consistent formatting\n",
    "menTablesV2$'1999'[1:10]\n",
    "menTablesV2[[2]][1:10]\n",
    "\n",
    "#### Save the outputs\n",
    "save(menTablesV2, file = \"CBMenTextTables.rda\")\n",
    "\n",
    "#### Now we need to investigate the differences between the male and female result pages\n",
    "# 2000\n",
    "df_male_2000 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2000/Cb003m.htm\", year = 2000, sex = \"male\", file = NULL)\n",
    "df_female_2000 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2000/Cb003f.htm\", year = 2000, sex = \"female\", file = NULL)\n",
    "\n",
    "df_female_2000[1:10]\n",
    "df_male_2000[1:10]\n",
    "\n",
    "# 2006\n",
    "df_male_2006 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2006/men.htm\", year = 2006, sex = \"male\", file = NULL)\n",
    "df_female_2006 <- extractResTableV2(url = \"http://www.cherryblossom.org/results/2006/women.htm\", year = 2006, sex = \"female\", file = NULL)\n",
    "\n",
    "df_female_2006[1:10]\n",
    "df_male_2006[1:10]\n",
    "\n",
    "######################################################################\n",
    "# Miscellaneous Code\n",
    "\n",
    "menTables <- list()\n",
    "for(i in 1:length(years)){\n",
    "  menTables[[i]] <- try(extractResTable(url=urlsV2[i], year=years[i]))\n",
    "}\n",
    "\n",
    "# Breaking down the extractResTableV2 for 1999 - Men\n",
    "url <- urlsV2[1]\n",
    "doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "pres = getNodeSet(doc, \"//pre\")\n",
    "txt = xmlValue(pres[[1]])\n",
    "els = strsplit(txt, \"\\r\\n\")[[1]]\n",
    "els = strsplit(txt, \"\\n\")[[1]]\n",
    "\n",
    "# Breaking down the extractResTableV2 for 2009 - Men\n",
    "url <- urlsV2[11]\n",
    "doc = htmlParse(url, encoding=\"UTF-8\")\n",
    "div1 = getNodeSet(doc, \"//div[@class='Section1']\")\n",
    "pres = getNodeSet(div1[[1]], \"//pre\")\n",
    "els = sapply(pres, xmlValue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['http://www.cherryblossom.org/cb003m.htm',\n 'http://www.cherryblossom.org/results/2001/oof_m.html',\n 'http://www.cherryblossom.org/results/2002/oofm.htm']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "ubase = \"http://www.cherryblossom.org/\"\n",
    "menURLs = [\"cb99m.htm\", \n",
    "    \"cb003m.htm\", \n",
    "    \"results/2001/oof_m.html\",\n",
    "    \"results/2002/oofm.htm\", \n",
    "    \"results/2003/CB03-M.HTM\",\n",
    "    \"results/2004/men.htm\", \n",
    "    \"results/2005/CB05-M.htm\", \n",
    "    \"results/2006/men.htm\", \n",
    "    \"results/2007/men.htm\", \n",
    "    \"results/2008/men.htm\", \n",
    "    \"results/2009/09cucb-M.htm\",\n",
    "    \"results/2010/2010cucb10m-m.htm\", \n",
    "    \"results/2011/2011cucb10m-m.htm\",\n",
    "    \"results/2012/2012cucb10m-m.htm\"]\n",
    "m_urls = [ubase + s for s in menURLs]\n",
    "m_urls[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['http://www.cherryblossom.org/results/2000/Cb003f.htm',\n 'http://www.cherryblossom.org/results/2001/oof_f.html',\n 'http://www.cherryblossom.org/results/2002/ooff.htm']"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "ubase = \"http://www.cherryblossom.org/\"\n",
    "womenURLs = [\"results/1999/cb99f.html\",\n",
    "    \"results/2000/Cb003f.htm\",\n",
    "    \"results/2001/oof_f.html\",\n",
    "    \"results/2002/ooff.htm\",\n",
    "    \"results/2003/CB03-F.HTM\",\n",
    "    \"results/2004/women.htm\",\n",
    "    \"results/2005/CB05-F.htm\",\n",
    "    \"results/2006/women.htm\",\n",
    "    \"results/2007/women.htm\",\n",
    "    \"results/2008/women.htm\",\n",
    "    \"results/2009/09cucb-F.htm\",\n",
    "    \"results/2010/2010cucb10m-f.htm\",\n",
    "    \"results/2011/2011cucb10m-f.htm\",\n",
    "    \"results/2012/2012cucb10m-f.htm\"\n",
    "]\n",
    "f_urls = [ubase + s for s in womenURLs]\n",
    "f_urls[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['PLACE', 'DIV', '/TOT', 'NAME', 'AG', 'HOMETOWN', 'TIME', 'PACE']"
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'http://www.cherryblossom.org/results/1999/cb99f.html'\n",
    "\n",
    "response = urllib.request.urlopen(URL)\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "table = soup.find(\"pre\").find(text=True)\n",
    "raw_rows = [x.strip() for x in table.split('\\n')]\n",
    "table_cols = raw_rows[1].split()\n",
    "table_cols[1] = table_cols[1] + table_cols[2]\n",
    "table_cols.remove(\"/TOT\")\n",
    "table_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PLACE DIV /TOT  NAME                  AG HOMETOWN           TIME    PACE\n"
    }
   ],
   "source": [
    "print(''.join(table_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['PLACE', 'DIV/TOT', 'NAME', 'AG', 'HOMETOWN', 'TIME', 'PACE']"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "table_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cols[1] = table_cols[1] + table_cols[2]\n",
    "table_cols.remove(\"/TOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "table = soup.find(\"pre\").find(text=True)\n",
    "raw_rows = [x.strip() for x in table.split('\\n')]\n",
    "table_cols = raw_rows[1].split()\n",
    "table_cols[1] = table_cols[1] + table_cols[2]\n",
    "table_cols.remove(\"/TOT\")\n",
    "parsed_rows = []\n",
    "for row in raw_rows[3:len(raw_rows[3:])+1]:\n",
    "    parsed_rows.append(re.split(r'\\s{2,}|(?<=[0-9])\\s', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['3', 'Lidiya Grigoryeva', 'Russia', '53:40', '5:22']\n['8', 'Gladys Asiba', 'Kenya', '54:50', '5:29']\n['17', 'Connie Buckwalter', 'Lancaster PA', '59:36', '5:58']\n['66', '55/1683', 'Deirdre Mccarthygalla 29', 'Arlington VA', '1:09:06', '6:55']\n['163', '123/1683', 'Patricia Rhea', '36', 'University Park MD 1:16:24', '7:39']\n['368', '283/1683', 'Christine Livingstone 27', 'Alexandria VA', '1:23:06', '8:19']\n['409', '20/185', 'Magdalena Chica-Garzo 47', 'Gaithersburg MD', '1:23:48', '8:23']\n['410', '316/1683', 'Ann Kim', '25', 'Charlottesville VA 1:23:49', '8:23']\n['475', '363/1683', 'Elizabeth Davidsen Bo 36', 'Chevy Chase MD', '1:25:05', '8:31']\n['476', '364/1683', 'Elizabeth Lower-Basch 27', 'Alexandria VA', '1:25:06', '8:31']\n['496', '381/1683', 'Dana Riesner', '30', 'Montgomery Vill MD 1:25:26', '8:33']\n['514', '62/306', 'Kim Freeze', '41', 'Fairfax Station VA 1:25:50', '8:35']\n['543', '418/1683', 'Lisa Radziwanowicz', '39', 'Fairfax Station VA 1:26:27', '8:39']\n['565', '437/1683', 'Patricia Navin-Greenf 39', 'Arlington VA', '1:26:49', '8:41']\n['581', '33/185', 'Marylove Moy', '45', 'University Park MD 1:27:06', '8:43']\n['652', '72/306', 'Addie Welch', '41', 'Sherwood Forest MD 1:28:16', '8:50']\n['673', '523/1683', 'Sharon Anderson', '23', 'Charlottesville VA 1:28:47', '8:53']\n['691', '44/185', 'Diane Sellazzo', '47', 'Cornwall On Hud NY 1:29:04', '8:55']\n['735', '567/1683', 'Jeannette Bisson-Camp 32', 'Washington DC', '1:29:37', '8:58']\n['748', '576/1683', 'Dee Reeb', '34', 'Fairfax Station VA 1:29:47', '8:59']\n['771', '88/306', 'Enid Schantz-Hagelber 43', 'Easton MD', '1:30:12', '9:02']\n['776', '24/115', 'Mary Brown', '51', 'Fairfax Station VA 1:30:16', '9:02']\n['809', '29/115', 'Arlette Cahen-Coppock 52', 'Falls Church VA', '1:30:37', '9:04']\n['860', '653/1683', 'Sangeetha Raghunathan 24', 'Washington DC', '1:31:16', '9:08']\n['872', '664/1683', 'Christine Castleberry 27', 'Arlington VA', '1:31:23', '9:09']\n['981', '110/306', 'Janet Brown', '44', 'Fairfax Station VA 1:32:51', '9:18']\n['984', '111/306', 'Ingrid Molinary-Tinsl 40', 'Arlington VA', '1:32:52', '9:18']\n['1047', '800/1683', 'Michelle Brafman-Helf 34', 'Glen Echo MD', '1:33:43', '9:23']\n['1158', '883/1683', 'Elizabeth Nightingale 32', 'Washington DC', '1:34:57', '9:30']\n['1202', '84/185', 'Linda Scandore', '48', 'Charlottesville VA 1:35:29', '9:33']\n['1207', '916/1683', 'Marie Hoefler', '32', 'University Park MD 1:35:32', '9:34']\n['1221', '144/306', 'Kate-Louise Gottfried 42', 'Washington DC', '1:35:47', '9:35']\n['1302', '985/1683', 'Charlotte Reece Moore 29', 'Arlington VA', '1:36:57', '9:42']\n['1310', '151/306', 'Theresa Robertsonphil 44', 'Glen Rock PA', '1:37:02', '9:43']\n['1406', '1058/1683', 'Heidi Wood', '34', 'Sherwood Forest MD 1:38:25', '9:51']\n['1519', '172/306', 'Christina Caravoulias 44', 'Silver Spring MD', '1:40:07', '10:01']\n['1520', '1147/1683', 'Shelly Taylor', '33', 'Fort Washington MD 1:40:08', '10:01']\n['1530', '1156/1683', 'Caron Vianda', '29', 'Channel Islands CA 1:40:17', '10:02']\n['1659', '125/185', 'Brenda Butler', '49', 'Fort Washington MD 1:42:13', '10:14']\n['1735', '199/306', 'Julie Wood', '41', 'Fairfax Station VA 1:43:24', '10:21']\n['1756', '26/47', 'M Magdalena Tomaszews 59', 'Gaithersburg MD', '1:43:39', '10:22']\n['1792', '209/306', 'Lynn Simon', '42', 'Fairfax Station VA 1:44:13', '10:26']\n['1793', '1337/1683', 'Robin Marshall', '35', 'Fairfax Station VA 1:44:13', '10:26']\n['1813', '1347/1683', 'Rebecca Cecin', '33', 'Fairfax Station VA 1:44:38', '10:28']\n['1890', '143/185', 'Barbara Silletto-Hoch 49', 'Laurel MD', '1:46:02', '10:37']\n['1907', '2/2', 'Edith Farias', '75', 'Salisbury Mills NY 1:46:36', '10:40']\n['1975', '243/306', 'Bette Jean Rosenhagen 42', 'New York NY', '1:47:54', '10:48']\n['2008', '156/185', 'Suzanne Seely', '49', 'Fairfax Station VA 1:48:56', '10:54']\n['2021', '1483/1683', 'Pam Sulka', '36', 'Fairfax Station VA 1:49:18', '10:56']\n['2092', '1528/1683', 'Joyce Challandes', '28', 'Croton-On-Hudsn NY 1:50:53', '11:06']\n['2175', 'Ann Reid', 'Bethesda MD', '1:53:03', '11:19']\n['2190', '1592/1683', 'Audrey Doukoure', '31', 'Montgomery Vill MD 1:54:01', '11:25']\n['2232', '287/306', 'Susan Maestri', '40', 'Paeonian Spring VA 1:55:55', '11:36']\n['2239', '173/185', 'Lois Potter', '45', 'Clifton Heights PA 1:56:31', '11:40']\n['2277', '294/306', 'Ingrid Meachum-Harper 42', 'Fort Washington MD 1:59:57', '12:00']\n['2306', '1655/1683', 'Stephanie Schalk-Zait 25', 'Rockville MD', '2:03:03', '12:19']\n"
    }
   ],
   "source": [
    "for row in parsed_rows:\n",
    "    if len(row)<7:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['1', '1/1683', 'Jane Omoro', '26', 'Kenya', '53:37', '5:22']\n['2', '2/1683', 'Jane Ngotho', '29', 'Kenya', '53:38', '5:22']\n['3', 'Lidiya Grigoryeva', 'Russia', '53:40', '5:22']\n['4', '3/1683', 'Eunice Sagero', '20', 'Kenya', '53:55', '5:24']\n['5', '4/1683', 'Alla Zhilyayeva', '29', 'Russia', '54:08', '5:25']\n['6', '5/1683', 'Teresa Wanjiku', '24', 'Kenya', '54:10', '5:25']\n['7', '6/1683', 'Elana Viazova', '38', 'Ukraine', '54:29', '5:27']\n"
    }
   ],
   "source": [
    "for row in raw_rows[3:10]:\n",
    "    print(re.split(r'\\s{2,}|(?<=[0-9])\\s', row))\n",
    "    #parsed_rows.append(re.split(r'\\s{2,}|(?<=[0-9])\\s', row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     PLACE            DIV/TOT              NAME     AG       HOMETOWN  \\\n0        1             1/1683        Jane Omoro     26          Kenya   \n1        2             2/1683       Jane Ngotho     29          Kenya   \n2        3  Lidiya Grigoryeva            Russia  53:40           5:22   \n3        4             3/1683     Eunice Sagero     20          Kenya   \n4        5             4/1683   Alla Zhilyayeva     29         Russia   \n...    ...                ...               ...    ...            ...   \n2350  2351            185/185   Dianette Stokes     46  Chesapeake VA   \n2351  2352            115/115  Jeanette Lampron     50    Woodbine MD   \n2352  2353          1680/1683      Tina Werking     29    Bethesda MD   \n2353  2354          1681/1683       Maria Walsh     30    New York NY   \n2354  2355          1682/1683    Jane Mcclellan     36     Phoenix AZ   \n\n         TIME   PACE  \n0       53:37   5:22  \n1       53:38   5:22  \n2        None   None  \n3       53:55   5:24  \n4       54:08   5:25  \n...       ...    ...  \n2350  2:17:32  13:46  \n2351  2:19:58  14:00  \n2352  2:21:40  14:10  \n2353  2:23:46  14:23  \n2354  2:26:14  14:38  \n\n[2355 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PLACE</th>\n      <th>DIV/TOT</th>\n      <th>NAME</th>\n      <th>AG</th>\n      <th>HOMETOWN</th>\n      <th>TIME</th>\n      <th>PACE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1/1683</td>\n      <td>Jane Omoro</td>\n      <td>26</td>\n      <td>Kenya</td>\n      <td>53:37</td>\n      <td>5:22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2/1683</td>\n      <td>Jane Ngotho</td>\n      <td>29</td>\n      <td>Kenya</td>\n      <td>53:38</td>\n      <td>5:22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Lidiya Grigoryeva</td>\n      <td>Russia</td>\n      <td>53:40</td>\n      <td>5:22</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3/1683</td>\n      <td>Eunice Sagero</td>\n      <td>20</td>\n      <td>Kenya</td>\n      <td>53:55</td>\n      <td>5:24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4/1683</td>\n      <td>Alla Zhilyayeva</td>\n      <td>29</td>\n      <td>Russia</td>\n      <td>54:08</td>\n      <td>5:25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2350</th>\n      <td>2351</td>\n      <td>185/185</td>\n      <td>Dianette Stokes</td>\n      <td>46</td>\n      <td>Chesapeake VA</td>\n      <td>2:17:32</td>\n      <td>13:46</td>\n    </tr>\n    <tr>\n      <th>2351</th>\n      <td>2352</td>\n      <td>115/115</td>\n      <td>Jeanette Lampron</td>\n      <td>50</td>\n      <td>Woodbine MD</td>\n      <td>2:19:58</td>\n      <td>14:00</td>\n    </tr>\n    <tr>\n      <th>2352</th>\n      <td>2353</td>\n      <td>1680/1683</td>\n      <td>Tina Werking</td>\n      <td>29</td>\n      <td>Bethesda MD</td>\n      <td>2:21:40</td>\n      <td>14:10</td>\n    </tr>\n    <tr>\n      <th>2353</th>\n      <td>2354</td>\n      <td>1681/1683</td>\n      <td>Maria Walsh</td>\n      <td>30</td>\n      <td>New York NY</td>\n      <td>2:23:46</td>\n      <td>14:23</td>\n    </tr>\n    <tr>\n      <th>2354</th>\n      <td>2355</td>\n      <td>1682/1683</td>\n      <td>Jane Mcclellan</td>\n      <td>36</td>\n      <td>Phoenix AZ</td>\n      <td>2:26:14</td>\n      <td>14:38</td>\n    </tr>\n  </tbody>\n</table>\n<p>2355 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "source": [
    "# ISSUE: Data entries are misplaced in columns due to missing values\n",
    "df = pd.DataFrame(parsed_rows, columns=table_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def scrape2002(URL):\n",
    "    response = urllib.request.urlopen(URL)\n",
    "    html = response.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    table = soup.find(\"pre\").find(text=True)\n",
    "    raw_rows = [x.strip() for x in table.split('\\n')]\n",
    "    table_cols = raw_rows[1].split()\n",
    "    parsed_rows = []\n",
    "    for row in raw_rows[3:len(raw_rows[3:])+1]:\n",
    "        parsed_rows.append(re.split(r'\\s{2,}|(?<=[0-9])\\s', row))\n",
    "    df = pd.DataFrame(parsed_rows, columns = table_cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2002 = scrape2002(f_urls[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Place    Num                  Name  Ag         Hometown      Net      Gun\n0        1   6005       Luminita TALPOS  29              Rom    52:50    52:50\n1        2   6003         Teyba ERKASSO  20              Eth    52:53    52:55\n2        3   6007       Sylvia MOSQUEDA  35              Usa    53:14    53:17\n3        4   6022        Teresa WANJIKU  27              Ken    53:36    53:36\n4        5   6020          Marla RUNYAN  33              Usa    53:37    53:37\n...    ...    ...                   ...  ..              ...      ...      ...\n3329  3330  10208  Ann HICKEY SHANKROFF  31  Falls Church VA  2:20:40  2:26:55\n3330  3331  11140        Nanette VARIAS  48       Fairfax VA  2:25:49  2:29:46\n3331  3332   7045         Joyce KIRKSEY  41    Alexandria VA  2:30:08  2:30:08\n3332  3333   8016          Gail SUMMERS  39     Lafayette IN  2:38:58  2:38:58\n3333  3334   7100      Rebecca PEARLMAN  31     Baltimore MD  2:42:22  2:42:22\n\n[3334 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Place</th>\n      <th>Num</th>\n      <th>Name</th>\n      <th>Ag</th>\n      <th>Hometown</th>\n      <th>Net</th>\n      <th>Gun</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>6005</td>\n      <td>Luminita TALPOS</td>\n      <td>29</td>\n      <td>Rom</td>\n      <td>52:50</td>\n      <td>52:50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>6003</td>\n      <td>Teyba ERKASSO</td>\n      <td>20</td>\n      <td>Eth</td>\n      <td>52:53</td>\n      <td>52:55</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>6007</td>\n      <td>Sylvia MOSQUEDA</td>\n      <td>35</td>\n      <td>Usa</td>\n      <td>53:14</td>\n      <td>53:17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>6022</td>\n      <td>Teresa WANJIKU</td>\n      <td>27</td>\n      <td>Ken</td>\n      <td>53:36</td>\n      <td>53:36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>6020</td>\n      <td>Marla RUNYAN</td>\n      <td>33</td>\n      <td>Usa</td>\n      <td>53:37</td>\n      <td>53:37</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3329</th>\n      <td>3330</td>\n      <td>10208</td>\n      <td>Ann HICKEY SHANKROFF</td>\n      <td>31</td>\n      <td>Falls Church VA</td>\n      <td>2:20:40</td>\n      <td>2:26:55</td>\n    </tr>\n    <tr>\n      <th>3330</th>\n      <td>3331</td>\n      <td>11140</td>\n      <td>Nanette VARIAS</td>\n      <td>48</td>\n      <td>Fairfax VA</td>\n      <td>2:25:49</td>\n      <td>2:29:46</td>\n    </tr>\n    <tr>\n      <th>3331</th>\n      <td>3332</td>\n      <td>7045</td>\n      <td>Joyce KIRKSEY</td>\n      <td>41</td>\n      <td>Alexandria VA</td>\n      <td>2:30:08</td>\n      <td>2:30:08</td>\n    </tr>\n    <tr>\n      <th>3332</th>\n      <td>3333</td>\n      <td>8016</td>\n      <td>Gail SUMMERS</td>\n      <td>39</td>\n      <td>Lafayette IN</td>\n      <td>2:38:58</td>\n      <td>2:38:58</td>\n    </tr>\n    <tr>\n      <th>3333</th>\n      <td>3334</td>\n      <td>7100</td>\n      <td>Rebecca PEARLMAN</td>\n      <td>31</td>\n      <td>Baltimore MD</td>\n      <td>2:42:22</td>\n      <td>2:42:22</td>\n    </tr>\n  </tbody>\n</table>\n<p>3334 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "f2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('MachineLearning': conda)",
   "language": "python",
   "name": "python37464bitmachinelearningconda0677930e300843d298327b869ad2eda0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}